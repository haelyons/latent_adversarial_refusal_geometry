{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b6a68ab0",
      "metadata": {},
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "65b33ea2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/lib/python3/dist-packages (from -r requirements.txt (line 1)) (2.7.0)\n",
            "Requirement already satisfied: numpy>=1.24.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
            "Requirement already satisfied: transformers>=4.36.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (4.57.3)\n",
            "Requirement already satisfied: transformer_lens>=1.14.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (2.16.1)\n",
            "Requirement already satisfied: peft>=0.7.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: accelerate>=0.25.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
            "Requirement already satisfied: huggingface_hub>=0.19.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (0.36.0)\n",
            "Requirement already satisfied: datasets>=2.14.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 8)) (4.4.1)\n",
            "Requirement already satisfied: einops>=0.7.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 9)) (0.8.1)\n",
            "Requirement already satisfied: jaxtyping>=0.2.25 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 10)) (0.3.4)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.3.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 12)) (3.10.8)\n",
            "Requirement already satisfied: scikit-learn>=1.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 13)) (1.7.2)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 14)) (4.67.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 15)) (2.32.5)\n",
            "Requirement already satisfied: colorama>=0.4.6 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: Pillow>=10.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 17)) (12.0.0)\n",
            "Requirement already satisfied: python-dotenv>=1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from -r requirements.txt (line 18)) (1.2.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.7.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (5.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/lib/python3/dist-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformers>=4.36.0->-r requirements.txt (line 3)) (0.22.1)\n",
            "Requirement already satisfied: sentencepiece in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.2.1)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.23.1)\n",
            "Requirement already satisfied: transformers-stream-generator<0.0.6,>=0.0.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.0.5)\n",
            "Requirement already satisfied: rich>=12.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (14.2.0)\n",
            "Requirement already satisfied: typing-extensions in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: typeguard<5.0,>=4.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (4.4.4)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.0.3)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.0.3)\n",
            "Requirement already satisfied: psutil in /usr/lib/python3/dist-packages (from peft>=0.7.0->-r requirements.txt (line 5)) (5.9.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/lib/python3/dist-packages (from huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (2024.3.1)\n",
            "Requirement already satisfied: xxhash in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.14.0->-r requirements.txt (line 8)) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.19 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.14.0->-r requirements.txt (line 8)) (0.70.18)\n",
            "Requirement already satisfied: pyarrow>=21.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.14.0->-r requirements.txt (line 8)) (22.0.0)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.14.0->-r requirements.txt (line 8)) (0.4.0)\n",
            "Requirement already satisfied: httpx<1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from datasets>=2.14.0->-r requirements.txt (line 8)) (0.28.1)\n",
            "Requirement already satisfied: wadler-lindig>=0.1.3 in /home/ubuntu/.local/lib/python3.10/site-packages (from jaxtyping>=0.2.25->-r requirements.txt (line 10)) (0.1.7)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/ubuntu/.local/lib/python3.10/site-packages (from pandas>=2.0.0->-r requirements.txt (line 11)) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=3 in /home/ubuntu/.local/lib/python3.10/site-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (3.2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib/python3/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 12)) (4.29.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/lib/python3/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.8.0 in /usr/lib/python3/dist-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.8.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn>=1.3.0->-r requirements.txt (line 13)) (1.5.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 15)) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from requests>=2.31.0->-r requirements.txt (line 15)) (2.6.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.31.0->-r requirements.txt (line 15)) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.31.0->-r requirements.txt (line 15)) (2020.6.20)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ubuntu/.local/lib/python3.10/site-packages (from fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (3.13.2)\n",
            "Requirement already satisfied: anyio in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.14.0->-r requirements.txt (line 8)) (4.12.0)\n",
            "Requirement already satisfied: httpcore==1.* in /home/ubuntu/.local/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=2.14.0->-r requirements.txt (line 8)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /home/ubuntu/.local/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.14.0->-r requirements.txt (line 8)) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->-r requirements.txt (line 11)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from rich>=12.6.0->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (2.19.2)\n",
            "Requirement already satisfied: platformdirs in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (2.5.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (4.21.12)\n",
            "Requirement already satisfied: pydantic<3 in /home/ubuntu/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (2.12.5)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (3.1.45)\n",
            "Requirement already satisfied: click>=8.0.1 in /usr/lib/python3/dist-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (8.0.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (2.48.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (1.22.0)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (2.6.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (6.7.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/lib/python3/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (21.2.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (5.0.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec>=2023.5.0->huggingface_hub>=0.19.0->-r requirements.txt (line 7)) (1.8.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (4.0.12)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.1.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from pydantic<3->wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (2.41.5)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ubuntu/.local/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=2.14.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /home/ubuntu/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens>=1.14.0->-r requirements.txt (line 4)) (5.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "fdaa1cb8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/ubuntu/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
            "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n",
            "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "/usr/lib/python3/dist-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.17.3 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
            "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
            "2025-12-19 16:21:04.731573: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766161264.750603   48104 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766161264.756930   48104 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766161264.775801   48104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766161264.775816   48104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766161264.775818   48104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766161264.775820   48104 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import functools\n",
        "import einops\n",
        "import requests\n",
        "import pandas as pd\n",
        "import io\n",
        "import gc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "from datasets import load_dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.decomposition import PCA\n",
        "from tqdm import tqdm\n",
        "from torch import Tensor\n",
        "from typing import List, Dict, Optional, Tuple\n",
        "from transformer_lens import HookedTransformer, utils\n",
        "from transformer_lens.hook_points import HookPoint\n",
        "from jaxtyping import Float, Int\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import PeftModel\n",
        "from huggingface_hub import login as hf_login\n",
        "import os\n",
        "\n",
        "from scipy.linalg import svd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c4bf02d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
          ]
        }
      ],
      "source": [
        "# set HF_TOKEN in .env\n",
        "token = os.environ.get(\"HF_TOKEN\")\n",
        "hf_login(token=token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9ea09c39",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "Output dir: /home/ubuntu/latent_refusal_geometry/outputs\n"
          ]
        }
      ],
      "source": [
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "INFERENCE_DTYPE = torch.float16\n",
        "SEED = 3252\n",
        "\n",
        "LLAMA_2_7B_CHAT_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "PEFT_MODEL_PATH_LAT = \"nlpett/llama-2-7b-chat-hf-LAT-layer4-hh\"\n",
        "PEFT_MODEL_PATH_AT = \"nlpett/llama-2-7b-chat-hf-AT-hh\"\n",
        "print(f\"Device: {DEVICE}\")\n",
        "\n",
        "LLAMA_CHAT_TEMPLATE = \"\\n[INST]{prompt}[/INST]\\n\"\n",
        "\n",
        "OUTPUT_DIR = Path(\"outputs\")\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output dir: {OUTPUT_DIR.resolve()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b288b7e",
      "metadata": {},
      "source": [
        "### Load data & test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "09effb60",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Harmful instructions: 416 train, 104 test\n",
            "Harmless instructions: 25058 train, 6265 test\n"
          ]
        }
      ],
      "source": [
        "def get_harmful_instructions() -> Tuple[List[str], List[str]]:\n",
        "    url = 'https://raw.githubusercontent.com/llm-attacks/llm-attacks/main/data/advbench/harmful_behaviors.csv'\n",
        "    response = requests.get(url)\n",
        "    dataset = pd.read_csv(io.StringIO(response.content.decode('utf-8')))\n",
        "    instructions = dataset['goal'].tolist()\n",
        "    train, test = train_test_split(instructions, test_size=0.2, random_state=42)\n",
        "    return train, test\n",
        "\n",
        "def get_harmless_instructions() -> Tuple[List[str], List[str]]:\n",
        "    hf_path = 'tatsu-lab/alpaca'\n",
        "    dataset = load_dataset(hf_path)\n",
        "    instructions = [\n",
        "        dataset['train'][i]['instruction'] \n",
        "        for i in range(len(dataset['train']))\n",
        "        if dataset['train'][i]['input'].strip() == '' # filter instructions wihtout inputs\n",
        "    ]\n",
        "    train, test = train_test_split(instructions, test_size=0.2, random_state=42)\n",
        "    return train, test\n",
        "\n",
        "harmful_train, harmful_test = get_harmful_instructions()\n",
        "harmless_train, harmless_test = get_harmless_instructions()\n",
        "\n",
        "print(f\"Harmful instructions: {len(harmful_train)} train, {len(harmful_test)} test\")\n",
        "print(f\"Harmless instructions: {len(harmless_train)} train, {len(harmless_test)} test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59bbecdc",
      "metadata": {},
      "source": [
        "### Load models & get activations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f5142311",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Merged LAT adapter\n",
            "Loaded pretrained model meta-llama/Llama-2-7b-chat-hf into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "def load_base_model() -> HookedTransformer:\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        LLAMA_2_7B_CHAT_PATH,\n",
        "        torch_dtype=INFERENCE_DTYPE,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    \n",
        "    hooked_model = HookedTransformer.from_pretrained_no_processing(\n",
        "        LLAMA_2_7B_CHAT_PATH,\n",
        "        hf_model=base_model,\n",
        "        dtype=INFERENCE_DTYPE,\n",
        "        device=DEVICE,\n",
        "        default_padding_side='left',\n",
        "    )\n",
        "    hooked_model.tokenizer.padding_side = 'left'\n",
        "    hooked_model.tokenizer.pad_token = \"[PAD]\"\n",
        "    \n",
        "    del base_model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return hooked_model\n",
        "\n",
        "def load_peft_model(peft_path: str, model_name: str = \"LAT\") -> HookedTransformer:\n",
        "    base_model = AutoModelForCausalLM.from_pretrained(\n",
        "        LLAMA_2_7B_CHAT_PATH,\n",
        "        torch_dtype=INFERENCE_DTYPE,\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "\n",
        "    # merge PEFT adapter    \n",
        "    peft_model = PeftModel.from_pretrained(base_model, peft_path)\n",
        "    peft_model = peft_model.to(INFERENCE_DTYPE)\n",
        "    \n",
        "    try:\n",
        "        merged_model = peft_model.merge_and_unload()\n",
        "        print(f\"Merged {model_name} adapter\")\n",
        "    except AttributeError:\n",
        "        merged_model = peft_model\n",
        "    \n",
        "    merged_model.eval()\n",
        "    \n",
        "    hooked_model = HookedTransformer.from_pretrained_no_processing(\n",
        "        LLAMA_2_7B_CHAT_PATH,\n",
        "        hf_model=merged_model,\n",
        "        dtype=INFERENCE_DTYPE,\n",
        "        device=DEVICE,\n",
        "        default_padding_side='left',\n",
        "    )\n",
        "    \n",
        "    hooked_model.tokenizer.padding_side = 'left'\n",
        "    hooked_model.tokenizer.pad_token = \"[PAD]\"\n",
        "    \n",
        "    del merged_model, peft_model, base_model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    return hooked_model\n",
        "\n",
        "# Load both models into a dictionary\n",
        "# Can fit both on a 80GB A100 ~14GB each in fp16\n",
        "\n",
        "models = {}\n",
        "models['Baseline'] = load_base_model()\n",
        "models['LAT'] = load_peft_model(PEFT_MODEL_PATH_LAT, \"LAT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ec8f8b47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "GPU Memory: 28.2GB allocated, 41.4GB reserved\n"
          ]
        }
      ],
      "source": [
        "allocated = torch.cuda.memory_allocated() / 1e9\n",
        "reserved = torch.cuda.memory_reserved() / 1e9\n",
        "print(f\"\\nGPU Memory: {allocated:.1f}GB allocated, {reserved:.1f}GB reserved\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f93d48cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "def tokenize_instructions(\n",
        "    tokenizer: AutoTokenizer,\n",
        "    instructions: List[str]\n",
        ") -> Int[Tensor, 'batch_size seq_len']:\n",
        "    \"\"\"Tokenize instructions using Llama-2 chat template.\"\"\"\n",
        "    prompts = [LLAMA_CHAT_TEMPLATE.format(prompt=instruction) for instruction in instructions]\n",
        "    return tokenizer(prompts, padding=True, truncation=False, return_tensors=\"pt\").input_ids\n",
        "\n",
        "def get_activations(\n",
        "    model: HookedTransformer,\n",
        "    instructions: List[str],\n",
        "    layer: int,\n",
        "    batch_size: int = 32,\n",
        "    position: int = -1  # Last token by default\n",
        ") -> torch.Tensor:\n",
        "    # Get activations at layer n for a given instruction\n",
        "    # run_with_cache for residual stream activations as we go\n",
        "\n",
        "    tokenize_fn = functools.partial(tokenize_instructions, tokenizer=model.tokenizer)\n",
        "    activations = []\n",
        "    \n",
        "    for i in tqdm(range(0, len(instructions), batch_size), desc=f\"Layer {layer}\"):\n",
        "        batch = instructions[i:i+batch_size]\n",
        "        toks = tokenize_fn(instructions=batch).to(DEVICE)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            _, cache = model.run_with_cache( # fw pass and cache intermediate residual stream activations\n",
        "                toks,\n",
        "                names_filter=lambda name: f'blocks.{layer}.hook_resid_pre' in name\n",
        "            )\n",
        "        activations.append(cache[f'blocks.{layer}.hook_resid_pre'][:, position, :]) \n",
        "    \n",
        "    return torch.cat(activations, dim=0)\n",
        "\n",
        "def get_activations_all_layers(\n",
        "    model: HookedTransformer,\n",
        "    instructions: List[str],\n",
        "    layers: List[int],\n",
        "    batch_size: int = 16,\n",
        "    position: int = -1\n",
        ") -> Dict[int, torch.Tensor]:\n",
        "    # Get activations at multiple layers\n",
        "    tokenize_fn = functools.partial(tokenize_instructions, tokenizer=model.tokenizer)\n",
        "    activations = {l: [] for l in layers}\n",
        "    \n",
        "    for i in tqdm(range(0, len(instructions), batch_size), desc=\"Extracting activations\"):\n",
        "        batch = instructions[i:i+batch_size]\n",
        "        toks = tokenize_fn(instructions=batch).to(DEVICE)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            _, cache = model.run_with_cache(\n",
        "                toks,\n",
        "                names_filter=lambda name: 'resid_pre' in name\n",
        "            )\n",
        "        \n",
        "        for l in layers:\n",
        "            activations[l].append(cache['resid_pre', l][:, position, :])\n",
        "    \n",
        "    return {l: torch.cat(acts, dim=0) for l, acts in activations.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de8b2649",
      "metadata": {},
      "source": [
        "### Compute refusal vectors\n",
        "\n",
        "The difference of mean activations between harmful and harmless prompts. L14 has highest efficacy of refusal direction ablation aross all model variants - see 14.3 in https://arxiv.org/pdf/2504.18872"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ffd7fa94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline at layer 14:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer 14: 100%|██████████| 26/26 [00:02<00:00, 11.25it/s]\n",
            "Layer 14: 100%|██████████| 26/26 [00:02<00:00, 12.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LAT at layer 14:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Layer 14: 100%|██████████| 26/26 [00:02<00:00, 12.86it/s]\n",
            "Layer 14: 100%|██████████| 26/26 [00:02<00:00, 11.84it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape: torch.Size([416, 4096])\n",
            "Baseline refusal direction norm = 12.8594\n",
            "LAT refusal direction norm = 26.6562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# global refusal vector computation confiog\n",
        "N_SAMPLES = 416  # samples to compute vector (matched to previous experiments)\n",
        "TARGET_LAYER = 14  # target activation layer\n",
        "\n",
        "harmful_acts = {}   # {model_name: tensor}\n",
        "harmless_acts = {}  # {model_name: tensor}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"{model_name} at layer {TARGET_LAYER}:\")\n",
        "    \n",
        "    harmful_acts[model_name] = get_activations(model, harmful_train[:N_SAMPLES], TARGET_LAYER, batch_size=16)\n",
        "    harmless_acts[model_name] = get_activations(model, harmless_train[:N_SAMPLES], TARGET_LAYER, batch_size=16)\n",
        "\n",
        "print(f\"shape:\", harmful_acts['Baseline'].shape)\n",
        "refusal_dirs = {}\n",
        "\n",
        "# old difference of means method, Arditi et al. style refusal direction\n",
        "# my understanding right now is that this is equivalent to the first right \n",
        "# singular vector of the difference matrix - using SVD shows us the larger structure\n",
        "# so for Gorton et al. metrics (features per dimension, off-diagonal interference) \n",
        "# we need basis vectors, computed from (harmful - harmless) activations via SVD\n",
        "\n",
        "for model_name in models.keys():\n",
        "    harmful_mean = harmful_acts[model_name].mean(dim=0)\n",
        "    harmless_mean = harmless_acts[model_name].mean(dim=0)\n",
        "    \n",
        "    refusal_dir = harmful_mean - harmless_mean\n",
        "    refusal_dirs[model_name] = {\n",
        "        'raw': refusal_dir,\n",
        "        'normalized': refusal_dir / refusal_dir.norm(),\n",
        "        'norm': refusal_dir.norm().item()\n",
        "    }\n",
        "    print(f\"{model_name} refusal direction norm = {refusal_dir.norm().item():.4f}\")\n",
        "\n",
        "# Baseline norm 12.9531\n",
        "# LAT norm of 28.2188\n",
        "\n",
        "# what does this mean? 2.2x for LAT \n",
        "# the \"distance\" between the harmless/full clusters?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90b3dfe6",
      "metadata": {},
      "source": [
        "### Analysis of selected layer and refusal vector composition"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13f4e3e2",
      "metadata": {},
      "source": [
        "#### Cosine similarity of baseline and LAT refusal vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bc8e8f51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "baseline vs. LAT refusal direction cosine similarity: 0.0550\n"
          ]
        }
      ],
      "source": [
        "baseline_dir = harmful_acts['Baseline'].mean(dim=0) - harmless_acts['Baseline'].mean(dim=0)\n",
        "lat_dir = harmful_acts['LAT'].mean(dim=0) - harmless_acts['LAT'].mean(dim=0)\n",
        "\n",
        "cos_sim = torch.cosine_similarity(\n",
        "    (baseline_dir / baseline_dir.norm()).unsqueeze(0),\n",
        "    (lat_dir / lat_dir.norm()).unsqueeze(0)\n",
        ").item()\n",
        "\n",
        "print(f\"baseline vs. LAT refusal direction cosine similarity: {cos_sim:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6167faa7",
      "metadata": {},
      "source": [
        "#### SVD concentration at layer 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "abd4c637",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline - Top 1: 50.5%, Top 2: 54.2%\n",
            "LAT      - Top 1: 99.2%, Top 2: 99.3%\n"
          ]
        }
      ],
      "source": [
        "def explained_variance_ratio(data):\n",
        "    _, s, _ = svd(data, full_matrices=False)\n",
        "    variance_ratio = (s**2) / np.sum(s**2)\n",
        "    return variance_ratio\n",
        "\n",
        "base_diffs = (harmful_acts['Baseline'] - harmless_acts['Baseline']).cpu().numpy()\n",
        "lat_diffs = (harmful_acts['LAT'] - harmless_acts['LAT']).cpu().numpy()\n",
        "\n",
        "base_var = explained_variance_ratio(base_diffs)\n",
        "lat_var = explained_variance_ratio(lat_diffs)\n",
        "\n",
        "print(f\"Baseline - Top 1: {base_var[0]*100:.1f}%, Top 2: {sum(base_var[:2])*100:.1f}%\")\n",
        "print(f\"LAT      - Top 1: {lat_var[0]*100:.1f}%, Top 2: {sum(lat_var[:2])*100:.1f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "048d1536",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 864x720 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Explained variance at SVD component 1:\n",
            "Baseline: 0.5050\n",
            "LAT: 0.9917\n",
            "\n",
            "Total variance explained by top 10 components:\n",
            "Baseline: 0.6911\n",
            "LAT: 0.9963\n"
          ]
        }
      ],
      "source": [
        "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
        "\n",
        "n_components = 10\n",
        "x = np.arange(n_components)\n",
        "width = 0.35\n",
        "\n",
        "# Bar plot - explained variance per component\n",
        "ax1.bar(x - width/2, base_var[:n_components] * 100, width, label='Baseline', color='tab:blue', alpha=0.7)\n",
        "ax1.bar(x + width/2, lat_var[:n_components] * 100, width, label='LAT', color='tab:orange', alpha=0.7)\n",
        "\n",
        "ax1.set_xlabel('SVD Component')\n",
        "ax1.set_ylabel('Explained Variance (%)')\n",
        "ax1.set_title(f'Layer {TARGET_LAYER}: Explained Variance by SVD Component')\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(range(1, n_components + 1))\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "base_cum_var = np.cumsum(base_var)\n",
        "lat_cum_var = np.cumsum(lat_var)\n",
        "\n",
        "ax2.plot(range(1, n_components+1), base_cum_var[:n_components] * 100, 'o-', color='tab:blue', label='Baseline')\n",
        "ax2.plot(range(1, n_components+1), lat_cum_var[:n_components] * 100, 'o-', color='tab:orange', label='LAT')\n",
        "ax2.axhline(y=95, color='red', linestyle='--', alpha=0.5, label='95% threshold')\n",
        "\n",
        "ax2.set_xlabel('Number of SVD Components')\n",
        "ax2.set_ylabel('Cumulative Explained Variance (%)')\n",
        "ax2.set_title(f'Layer {TARGET_LAYER}: Cumulative Explained Variance')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'svd_spectrum.png', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics matching original notebook format\n",
        "print(f\"\\nExplained variance at SVD component 1:\")\n",
        "print(f\"Baseline: {base_var[0]:.4f}\")\n",
        "print(f\"LAT: {lat_var[0]:.4f}\")\n",
        "\n",
        "print(f\"\\nTotal variance explained by top {n_components} components:\")\n",
        "print(f\"Baseline: {sum(base_var[:n_components]):.4f}\")\n",
        "print(f\"LAT: {sum(lat_var[:n_components]):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5dd62df7",
      "metadata": {},
      "source": [
        "---\n",
        "## Refusal Subspace Analysis\n",
        "\n",
        "\n",
        "The previous Gram matrix analysis (below) computed interference on per-sample difference vectors (harmful[i] - harmless[i]). This measures consistency of the refusal direction across samples—**not** the feature interference that Gorton (2025) measures.\n",
        "\n",
        "Gorton's interference metric is computed on the basis vectors spanning the refusal subspace (analogous to W^T W in learned feature representations). For LLMs, the correct approach is to:\n",
        "\n",
        "1. Compute per-sample difference vectors (harmful - harmless)\n",
        "2. Extract **basis vectors** via SVD (these are the \"features\" of refusal)\n",
        "3. Compute Gram matrix on these basis vectors\n",
        "4. Extract off-diagonal interference metrics\n",
        "\n",
        "### from Gorton (2025) & Geometry of Refusal (Wollschläger et al. 2025):\n",
        "\n",
        "1. **Refusal Subspace Interference (RSI)**: Off-diagonal elements of Gram matrix on refusal basis vectors\n",
        "2. **Effective Refusal Dimension (ERD)**: Entropy-based measure of how many dimensions encode refusal\n",
        "3. **Cross-Layer Interference Propagation**: How interference grows across layers\n",
        "\n",
        "**Hypothesis**: If LAT reduces superposition like adversarial training:\n",
        "- `mean_off_diagonal_interference` should be **~2× lower** for LAT vs Baseline\n",
        "- `effective_dimension_entropy` should be **lower** (more concentrated)\n",
        "- `top_1_sv_ratio` should be **higher** (more variance in first component)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03664e62",
      "metadata": {},
      "source": [
        "### Metric 1: Refusal Subspace Interference (RSI)\n",
        "\n",
        "Compute interference in the refusal subspace **basis vectors**, aligned with Gorton's W^T W analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "331e8c2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# we want to compute the feature interference on the basis vectors\n",
        "# rather than on the refusal direction\n",
        "\n",
        "N_COMPONENTS = 5  # refusal directions to analyze\n",
        "\n",
        "rsi_results = {}\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Refusal Subspace Interference: {model_name}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    # per sample difference vectors\n",
        "    diffs = (harmful_acts[model_name] - harmless_acts[model_name]).cpu().float().numpy()\n",
        "    \n",
        "    # extract basis via SVD (so all of the features of refusal)\n",
        "    U, s, Vt = np.linalg.svd(diffs, full_matrices=False)\n",
        "    basis_vectors = Vt[:N_COMPONENTS]  # Top-k refusal directions (k x d)\n",
        "    \n",
        "    # compute Gram matrix on basis vectors (analogous to W^T W)\n",
        "    gram = basis_vectors @ basis_vectors.T  # k x k\n",
        "    \n",
        "    # off-diagonal interference\n",
        "    n = gram.shape[0]\n",
        "    mask = ~np.eye(n, dtype=bool)\n",
        "    off_diag = gram[mask]\n",
        "    \n",
        "    mean_interference = np.abs(off_diag).mean()\n",
        "    max_interference = np.abs(off_diag).max()\n",
        "    interference_frobenius = np.linalg.norm(gram - np.diag(np.diag(gram)), 'fro')\n",
        "    \n",
        "    # 6. Variance concentration (how much is in top-k)\n",
        "    total_var = (s ** 2).sum()\n",
        "    top_k_var = (s[:N_COMPONENTS] ** 2).sum()\n",
        "    concentration = top_k_var / total_var\n",
        "    \n",
        "    rsi_results[model_name] = {\n",
        "        'mean_off_diagonal_interference': mean_interference,\n",
        "        'max_off_diagonal_interference': max_interference,\n",
        "        'interference_frobenius_norm': interference_frobenius,\n",
        "        'variance_concentration_top_k': concentration,\n",
        "        'singular_values': s[:N_COMPONENTS],\n",
        "        'gram_matrix': gram\n",
        "    }\n",
        "    \n",
        "    print(f\"Mean off-diagonal interference: {mean_interference:.6f}\")\n",
        "    print(f\"Max off-diagonal interference: {max_interference:.6f}\")\n",
        "    print(f\"Interference Frobenius norm: {interference_frobenius:.6f}\")\n",
        "    print(f\"Variance concentration (top {N_COMPONENTS}): {concentration:.4f}\")\n",
        "    print(f\"Top {N_COMPONENTS} singular values: {s[:N_COMPONENTS]}\")\n",
        "\n",
        "# Compare models\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"COMPARISON: RSI Metrics\")\n",
        "print('='*60)\n",
        "baseline_rsi = rsi_results['Baseline']['mean_off_diagonal_interference']\n",
        "lat_rsi = rsi_results['LAT']['mean_off_diagonal_interference']\n",
        "ratio = baseline_rsi / lat_rsi if lat_rsi > 0 else float('inf')\n",
        "print(f\"Baseline mean interference: {baseline_rsi:.6f}\")\n",
        "print(f\"LAT mean interference: {lat_rsi:.6f}\")\n",
        "print(f\"Ratio (Baseline/LAT): {ratio:.2f}x\")\n",
        "print(f\"\\nExpected (from Gorton): ~2x reduction in LAT\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a476dfd",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize RSI Gram matrices (basis vectors, not per-sample)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "for idx, model_name in enumerate(['Baseline', 'LAT']):\n",
        "    ax = axes[idx]\n",
        "    gram = rsi_results[model_name]['gram_matrix']\n",
        "    \n",
        "    im = ax.imshow(gram, cmap='RdBu_r', vmin=-1, vmax=1)\n",
        "    ax.set_title(f'{model_name}: Refusal Basis Gram Matrix\\n(Mean off-diag: {rsi_results[model_name][\"mean_off_diagonal_interference\"]:.4f})')\n",
        "    ax.set_xlabel('Basis Vector Index')\n",
        "    ax.set_ylabel('Basis Vector Index')\n",
        "    plt.colorbar(im, ax=ax, label='Inner Product')\n",
        "    \n",
        "    # Add value annotations\n",
        "    for i in range(gram.shape[0]):\n",
        "        for j in range(gram.shape[1]):\n",
        "            text = ax.text(j, i, f'{gram[i, j]:.2f}',\n",
        "                          ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "plt.suptitle(f'Refusal Subspace Interference (Layer {TARGET_LAYER}): Gram Matrix on Top-{N_COMPONENTS} Basis Vectors', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'rsi_gram_matrices.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: For orthogonal basis vectors, off-diagonal elements should be 0.\")\n",
        "print(\"Non-zero off-diagonals indicate interference between refusal directions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51b727a1",
      "metadata": {},
      "source": [
        "### Metric 4: Effective Refusal Dimension (ERD)\n",
        "\n",
        "Compute the effective dimensionality of the refusal subspace using multiple measures:\n",
        "- **Entropy-based**: exp(H) where H = -Σ p log(p) and p = normalized singular values\n",
        "- **Threshold-based**: Minimum dimensions to capture 95% variance\n",
        "- **Participation Ratio**: (Σσ²)² / Σσ⁴\n",
        "\n",
        "**Hypothesis**: LAT models should have lower effective dimension (more concentrated refusal representation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "047fb07f",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metric 4: Effective Refusal Dimension (ERD)\n",
        "# Compute effective dimensionality of the refusal subspace\n",
        "\n",
        "VARIANCE_THRESHOLD = 0.95  # Variance to capture\n",
        "\n",
        "erd_results = {}\n",
        "\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Effective Refusal Dimension: {model_name}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    # Get difference vectors\n",
        "    diffs = (harmful_acts[model_name] - harmless_acts[model_name]).cpu().float().numpy()\n",
        "    \n",
        "    # SVD\n",
        "    _, s, _ = np.linalg.svd(diffs, full_matrices=False)\n",
        "    \n",
        "    # Variance explained by each component\n",
        "    var_explained = (s ** 2) / (s ** 2).sum()\n",
        "    cumulative_var = np.cumsum(var_explained)\n",
        "    \n",
        "    # Effective dimension via entropy: H = -sum(p * log(p))\n",
        "    p = (s ** 2) / (s ** 2).sum()\n",
        "    p = p[p > 1e-10]  # Avoid log(0)\n",
        "    entropy = -np.sum(p * np.log(p))\n",
        "    effective_dim_entropy = np.exp(entropy)\n",
        "    \n",
        "    # Effective dimension via threshold\n",
        "    effective_dim_threshold = np.searchsorted(cumulative_var, VARIANCE_THRESHOLD) + 1\n",
        "    \n",
        "    # Participation ratio: (sum(σ²))² / sum(σ⁴)\n",
        "    participation_ratio = ((s ** 2).sum() ** 2) / ((s ** 4).sum())\n",
        "    \n",
        "    erd_results[model_name] = {\n",
        "        'effective_dimension_entropy': effective_dim_entropy,\n",
        "        'effective_dimension_95pct': effective_dim_threshold,\n",
        "        'participation_ratio': participation_ratio,\n",
        "        'top_1_variance_ratio': var_explained[0],\n",
        "        'top_5_variance_ratio': cumulative_var[4] if len(cumulative_var) > 4 else cumulative_var[-1],\n",
        "        'singular_values': s[:10]\n",
        "    }\n",
        "    \n",
        "    print(f\"Effective dim (entropy): {effective_dim_entropy:.2f}\")\n",
        "    print(f\"Effective dim (95% var): {effective_dim_threshold}\")\n",
        "    print(f\"Participation ratio: {participation_ratio:.2f}\")\n",
        "    print(f\"Top-1 variance ratio: {var_explained[0]*100:.1f}%\")\n",
        "    print(f\"Top-5 variance ratio: {cumulative_var[4]*100:.1f}%\")\n",
        "\n",
        "# Compare models\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"COMPARISON: ERD Metrics\")\n",
        "print('='*60)\n",
        "print(f\"{'Metric':<30} {'Baseline':>15} {'LAT':>15}\")\n",
        "print('-'*60)\n",
        "for metric in ['effective_dimension_entropy', 'effective_dimension_95pct', 'participation_ratio', 'top_1_variance_ratio']:\n",
        "    b_val = erd_results['Baseline'][metric]\n",
        "    l_val = erd_results['LAT'][metric]\n",
        "    if metric == 'top_1_variance_ratio':\n",
        "        print(f\"{metric:<30} {b_val*100:>14.1f}% {l_val*100:>14.1f}%\")\n",
        "    else:\n",
        "        print(f\"{metric:<30} {b_val:>15.2f} {l_val:>15.2f}\")\n",
        "\n",
        "print(f\"\\nHypothesis: LAT should have LOWER effective dim and HIGHER top-1 variance ratio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c563b6e6",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize ERD metrics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Plot 1: Singular value decay\n",
        "ax = axes[0]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    sv = erd_results[model_name]['singular_values']\n",
        "    ax.plot(range(1, len(sv)+1), sv, 'o-', label=model_name, markersize=6)\n",
        "ax.set_xlabel('Component')\n",
        "ax.set_ylabel('Singular Value')\n",
        "ax.set_title('Singular Value Decay')\n",
        "ax.legend()\n",
        "ax.set_yscale('log')\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Effective dimension comparison\n",
        "ax = axes[1]\n",
        "metrics = ['entropy', '95pct', 'participation']\n",
        "baseline_vals = [\n",
        "    erd_results['Baseline']['effective_dimension_entropy'],\n",
        "    erd_results['Baseline']['effective_dimension_95pct'],\n",
        "    erd_results['Baseline']['participation_ratio']\n",
        "]\n",
        "lat_vals = [\n",
        "    erd_results['LAT']['effective_dimension_entropy'],\n",
        "    erd_results['LAT']['effective_dimension_95pct'],\n",
        "    erd_results['LAT']['participation_ratio']\n",
        "]\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "ax.bar(x - width/2, baseline_vals, width, label='Baseline', alpha=0.7)\n",
        "ax.bar(x + width/2, lat_vals, width, label='LAT', alpha=0.7)\n",
        "ax.set_ylabel('Effective Dimension')\n",
        "ax.set_title('Effective Dimension Measures')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Plot 3: Cumulative variance explained\n",
        "ax = axes[2]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    diffs = (harmful_acts[model_name] - harmless_acts[model_name]).cpu().float().numpy()\n",
        "    _, s, _ = np.linalg.svd(diffs, full_matrices=False)\n",
        "    var_explained = (s ** 2) / (s ** 2).sum()\n",
        "    cumulative_var = np.cumsum(var_explained)[:20]\n",
        "    ax.plot(range(1, len(cumulative_var)+1), cumulative_var * 100, 'o-', label=model_name)\n",
        "ax.axhline(y=95, color='red', linestyle='--', alpha=0.5, label='95% threshold')\n",
        "ax.set_xlabel('Number of Components')\n",
        "ax.set_ylabel('Cumulative Variance (%)')\n",
        "ax.set_title('Cumulative Variance Explained')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle(f'Effective Refusal Dimension Analysis (Layer {TARGET_LAYER})', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'effective_refusal_dimension.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf5d7c9",
      "metadata": {},
      "source": [
        "### Metric 2: Cross-Layer Interference Propagation\n",
        "\n",
        "Measure how refusal interference changes across layers. From Gorton (2025):\n",
        "\n",
        "> \"This vulnerability compounds across layers. At each layer, the adversary can exploit superposition to create unwanted feature activations, which then propagate to the next layer.\"\n",
        "\n",
        "**Hypothesis**: LAT models should show slower interference growth across layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98c61d34",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metric 2: Cross-Layer Interference Propagation\n",
        "# Track how refusal interference changes across layers\n",
        "\n",
        "ANALYSIS_LAYERS = [4, 8, 12, 14, 16, 20, 24, 28]  # Layers to analyze\n",
        "N_SAMPLES_CROSS_LAYER = 50  # Fewer samples for efficiency\n",
        "\n",
        "cross_layer_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Cross-Layer Analysis: {model_name}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    # Get activations at multiple layers\n",
        "    harmful_multi = get_activations_all_layers(model, harmful_train[:N_SAMPLES_CROSS_LAYER], ANALYSIS_LAYERS, batch_size=16)\n",
        "    harmless_multi = get_activations_all_layers(model, harmless_train[:N_SAMPLES_CROSS_LAYER], ANALYSIS_LAYERS, batch_size=16)\n",
        "    \n",
        "    layer_metrics = {}\n",
        "    for layer in ANALYSIS_LAYERS:\n",
        "        # Compute difference vectors for this layer\n",
        "        diffs = (harmful_multi[layer] - harmless_multi[layer]).cpu().float().numpy()\n",
        "        \n",
        "        # SVD to get basis vectors\n",
        "        U, s, Vt = np.linalg.svd(diffs, full_matrices=False)\n",
        "        basis_vectors = Vt[:N_COMPONENTS]\n",
        "        \n",
        "        # Gram matrix on basis vectors\n",
        "        gram = basis_vectors @ basis_vectors.T\n",
        "        \n",
        "        # Off-diagonal interference\n",
        "        n = gram.shape[0]\n",
        "        mask = ~np.eye(n, dtype=bool)\n",
        "        off_diag = gram[mask]\n",
        "        mean_interference = np.abs(off_diag).mean()\n",
        "        \n",
        "        # Effective dimension\n",
        "        p = (s ** 2) / (s ** 2).sum()\n",
        "        p = p[p > 1e-10]\n",
        "        entropy = -np.sum(p * np.log(p))\n",
        "        effective_dim = np.exp(entropy)\n",
        "        \n",
        "        # Variance concentration\n",
        "        var_explained = (s ** 2) / (s ** 2).sum()\n",
        "        top_1_var = var_explained[0]\n",
        "        \n",
        "        layer_metrics[layer] = {\n",
        "            'mean_interference': mean_interference,\n",
        "            'effective_dim': effective_dim,\n",
        "            'top_1_variance': top_1_var,\n",
        "            'refusal_norm': np.linalg.norm(diffs.mean(axis=0))\n",
        "        }\n",
        "        \n",
        "        print(f\"Layer {layer:2d}: interference={mean_interference:.4f}, eff_dim={effective_dim:.2f}, top1_var={top_1_var*100:.1f}%\")\n",
        "    \n",
        "    cross_layer_results[model_name] = layer_metrics\n",
        "    \n",
        "    # Clean up\n",
        "    del harmful_multi, harmless_multi\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"Cross-Layer Comparison Complete\")\n",
        "print('='*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78ba67e1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cross-layer interference propagation\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Plot 1: Mean interference across layers\n",
        "ax = axes[0, 0]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    layers = list(cross_layer_results[model_name].keys())\n",
        "    interference = [cross_layer_results[model_name][l]['mean_interference'] for l in layers]\n",
        "    ax.plot(layers, interference, 'o-', label=model_name, markersize=8)\n",
        "ax.set_xlabel('Layer')\n",
        "ax.set_ylabel('Mean Off-Diagonal Interference')\n",
        "ax.set_title('Interference Propagation Across Layers')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Effective dimension across layers\n",
        "ax = axes[0, 1]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    layers = list(cross_layer_results[model_name].keys())\n",
        "    eff_dim = [cross_layer_results[model_name][l]['effective_dim'] for l in layers]\n",
        "    ax.plot(layers, eff_dim, 'o-', label=model_name, markersize=8)\n",
        "ax.set_xlabel('Layer')\n",
        "ax.set_ylabel('Effective Dimension (entropy)')\n",
        "ax.set_title('Effective Refusal Dimension Across Layers')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Top-1 variance across layers\n",
        "ax = axes[1, 0]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    layers = list(cross_layer_results[model_name].keys())\n",
        "    top1_var = [cross_layer_results[model_name][l]['top_1_variance'] * 100 for l in layers]\n",
        "    ax.plot(layers, top1_var, 'o-', label=model_name, markersize=8)\n",
        "ax.set_xlabel('Layer')\n",
        "ax.set_ylabel('Top-1 Variance (%)')\n",
        "ax.set_title('Variance Concentration Across Layers')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 4: Refusal direction norm across layers\n",
        "ax = axes[1, 1]\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    layers = list(cross_layer_results[model_name].keys())\n",
        "    norms = [cross_layer_results[model_name][l]['refusal_norm'] for l in layers]\n",
        "    ax.plot(layers, norms, 'o-', label=model_name, markersize=8)\n",
        "ax.set_xlabel('Layer')\n",
        "ax.set_ylabel('Refusal Direction Norm')\n",
        "ax.set_title('Refusal Direction Magnitude Across Layers')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Cross-Layer Refusal Geometry Analysis', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / 'cross_layer_interference.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Compute growth rates\n",
        "print(\"\\nInterference Growth Rates:\")\n",
        "for model_name in ['Baseline', 'LAT']:\n",
        "    layers = list(cross_layer_results[model_name].keys())\n",
        "    interference = [cross_layer_results[model_name][l]['mean_interference'] for l in layers]\n",
        "    growth_rate = np.diff(interference).mean()\n",
        "    print(f\"  {model_name}: {growth_rate:.6f} per layer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33b05f18",
      "metadata": {},
      "source": [
        "### Metric 3: Representational Independence (Geometry of Refusal)\n",
        "\n",
        "From Wollschläger et al. (2025):\n",
        "\n",
        "> \"Orthogonality alone does not imply independence under intervention... we introduce representational independence, a criterion for identifying directions that remain mutually unaffected under intervention.\"\n",
        "\n",
        "This test checks whether ablating one refusal direction affects the representation of another. If `independence_vs_orthogonality_gap` is large, the model has non-linear dependencies that pure cosine similarity misses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c093b604",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metric 3: Representational Independence Score\n",
        "# Test whether ablating one refusal direction affects the representation of another\n",
        "\n",
        "# Use a subset of test instructions for efficiency\n",
        "test_instructions = harmful_test[:20] + harmless_test[:20]\n",
        "\n",
        "rep_ind_results = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Representational Independence: {model_name}\")\n",
        "    print('='*60)\n",
        "    \n",
        "    # Get refusal subspace basis vectors (top 2 for this test)\n",
        "    diffs = (harmful_acts[model_name] - harmless_acts[model_name]).cpu().float()\n",
        "    U, s, Vt = torch.linalg.svd(diffs, full_matrices=False)\n",
        "    \n",
        "    direction_1 = Vt[0].to(DEVICE).to(INFERENCE_DTYPE)  # First refusal direction\n",
        "    direction_2 = Vt[1].to(DEVICE).to(INFERENCE_DTYPE)  # Second refusal direction\n",
        "    \n",
        "    # Normalize directions\n",
        "    direction_1 = direction_1 / direction_1.norm()\n",
        "    direction_2 = direction_2 / direction_2.norm()\n",
        "    \n",
        "    # Geometric orthogonality (cosine similarity)\n",
        "    cosine_sim = torch.cosine_similarity(direction_1.unsqueeze(0), direction_2.unsqueeze(0)).item()\n",
        "    geometric_orthogonality = 1 - abs(cosine_sim)\n",
        "    \n",
        "    # Get baseline activations\n",
        "    baseline_acts = get_activations(model, test_instructions, TARGET_LAYER, batch_size=16)\n",
        "    baseline_proj_1 = (baseline_acts @ direction_1).cpu()\n",
        "    baseline_proj_2 = (baseline_acts @ direction_2).cpu()\n",
        "    \n",
        "    # Ablate direction_1 and measure effect on direction_2's representation\n",
        "    # Using TransformerLens hook\n",
        "    def directional_ablation_hook(resid, hook):\n",
        "        # Remove component along direction_1 from residual stream\n",
        "        proj = (resid @ direction_1).unsqueeze(-1) * direction_1\n",
        "        return resid - proj\n",
        "    \n",
        "    model.reset_hooks()\n",
        "    model.add_hook(f'blocks.{TARGET_LAYER}.hook_resid_pre', directional_ablation_hook)\n",
        "    \n",
        "    ablated_acts = get_activations(model, test_instructions, TARGET_LAYER, batch_size=16)\n",
        "    ablated_proj_2 = (ablated_acts @ direction_2).cpu()\n",
        "    model.reset_hooks()\n",
        "    \n",
        "    # Compute independence score\n",
        "    proj_change = (ablated_proj_2 - baseline_proj_2).abs().mean().item()\n",
        "    baseline_magnitude = baseline_proj_2.abs().mean().item()\n",
        "    independence_score = 1.0 - (proj_change / max(baseline_magnitude, 1e-10))\n",
        "    independence_score = max(0, min(1, independence_score))  # Clamp to [0, 1]\n",
        "    \n",
        "    # Gap between geometric orthogonality and representational independence\n",
        "    independence_gap = independence_score - geometric_orthogonality\n",
        "    \n",
        "    rep_ind_results[model_name] = {\n",
        "        'geometric_orthogonality': geometric_orthogonality,\n",
        "        'representational_independence_score': independence_score,\n",
        "        'ablation_effect_magnitude': proj_change,\n",
        "        'independence_vs_orthogonality_gap': independence_gap\n",
        "    }\n",
        "    \n",
        "    print(f\"Geometric orthogonality (1 - |cos_sim|): {geometric_orthogonality:.4f}\")\n",
        "    print(f\"Representational independence score: {independence_score:.4f}\")\n",
        "    print(f\"Ablation effect magnitude: {proj_change:.4f}\")\n",
        "    print(f\"Independence vs orthogonality gap: {independence_gap:.4f}\")\n",
        "    print(f\"\\nNote: Large gap indicates non-linear dependencies not captured by cosine similarity\")\n",
        "\n",
        "# Compare models\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"COMPARISON: Representational Independence\")\n",
        "print('='*60)\n",
        "print(f\"{'Metric':<40} {'Baseline':>15} {'LAT':>15}\")\n",
        "print('-'*70)\n",
        "for metric in ['geometric_orthogonality', 'representational_independence_score', 'independence_vs_orthogonality_gap']:\n",
        "    b_val = rep_ind_results['Baseline'][metric]\n",
        "    l_val = rep_ind_results['LAT'][metric]\n",
        "    print(f\"{metric:<40} {b_val:>15.4f} {l_val:>15.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08cfa7f9",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary: Expected vs Observed Results\n",
        "\n",
        "### Gorton's Hypothesis Applied to LAT\n",
        "\n",
        "If LAT operates analogously to adversarial training in reducing superposition, we expect:\n",
        "\n",
        "| Metric | Expected Direction | Gorton's Finding |\n",
        "|--------|-------------------|------------------|\n",
        "| mean_off_diagonal_interference | LAT < Baseline | ~2× reduction |\n",
        "| effective_dimension_entropy | LAT < Baseline | Lower = more concentrated |\n",
        "| top_1_sv_ratio | LAT > Baseline | Higher = simpler structure |\n",
        "| interference_growth_rate | LAT < Baseline | Slower propagation |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22d89eab",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Final Summary: Expected vs Observed Results\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"FINAL SUMMARY: LAT vs Baseline Refusal Geometry (Layer 14)\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Build summary dataframe\n",
        "summary_data = []\n",
        "\n",
        "# RSI metrics\n",
        "summary_data.append({\n",
        "    'Metric': 'mean_off_diagonal_interference',\n",
        "    'Baseline': rsi_results['Baseline']['mean_off_diagonal_interference'],\n",
        "    'LAT': rsi_results['LAT']['mean_off_diagonal_interference'],\n",
        "    'Expected': 'LAT < Baseline (~2×)',\n",
        "    'Ratio (B/L)': rsi_results['Baseline']['mean_off_diagonal_interference'] / max(rsi_results['LAT']['mean_off_diagonal_interference'], 1e-10)\n",
        "})\n",
        "\n",
        "summary_data.append({\n",
        "    'Metric': 'interference_frobenius_norm',\n",
        "    'Baseline': rsi_results['Baseline']['interference_frobenius_norm'],\n",
        "    'LAT': rsi_results['LAT']['interference_frobenius_norm'],\n",
        "    'Expected': 'LAT < Baseline',\n",
        "    'Ratio (B/L)': rsi_results['Baseline']['interference_frobenius_norm'] / max(rsi_results['LAT']['interference_frobenius_norm'], 1e-10)\n",
        "})\n",
        "\n",
        "# ERD metrics\n",
        "summary_data.append({\n",
        "    'Metric': 'effective_dimension_entropy',\n",
        "    'Baseline': erd_results['Baseline']['effective_dimension_entropy'],\n",
        "    'LAT': erd_results['LAT']['effective_dimension_entropy'],\n",
        "    'Expected': 'LAT < Baseline',\n",
        "    'Ratio (B/L)': erd_results['Baseline']['effective_dimension_entropy'] / max(erd_results['LAT']['effective_dimension_entropy'], 1e-10)\n",
        "})\n",
        "\n",
        "summary_data.append({\n",
        "    'Metric': 'top_1_variance_ratio',\n",
        "    'Baseline': erd_results['Baseline']['top_1_variance_ratio'],\n",
        "    'LAT': erd_results['LAT']['top_1_variance_ratio'],\n",
        "    'Expected': 'LAT > Baseline',\n",
        "    'Ratio (B/L)': erd_results['Baseline']['top_1_variance_ratio'] / max(erd_results['LAT']['top_1_variance_ratio'], 1e-10)\n",
        "})\n",
        "\n",
        "summary_data.append({\n",
        "    'Metric': 'variance_concentration_top5',\n",
        "    'Baseline': rsi_results['Baseline']['variance_concentration_top_k'],\n",
        "    'LAT': rsi_results['LAT']['variance_concentration_top_k'],\n",
        "    'Expected': 'LAT > Baseline',\n",
        "    'Ratio (B/L)': rsi_results['Baseline']['variance_concentration_top_k'] / max(rsi_results['LAT']['variance_concentration_top_k'], 1e-10)\n",
        "})\n",
        "\n",
        "# Cross-layer growth rate\n",
        "baseline_interference = [cross_layer_results['Baseline'][l]['mean_interference'] for l in ANALYSIS_LAYERS]\n",
        "lat_interference = [cross_layer_results['LAT'][l]['mean_interference'] for l in ANALYSIS_LAYERS]\n",
        "baseline_growth = np.diff(baseline_interference).mean()\n",
        "lat_growth = np.diff(lat_interference).mean()\n",
        "\n",
        "summary_data.append({\n",
        "    'Metric': 'interference_growth_rate',\n",
        "    'Baseline': baseline_growth,\n",
        "    'LAT': lat_growth,\n",
        "    'Expected': 'LAT < Baseline',\n",
        "    'Ratio (B/L)': baseline_growth / max(lat_growth, 1e-10) if lat_growth != 0 else float('inf')\n",
        "})\n",
        "\n",
        "# Representational independence\n",
        "summary_data.append({\n",
        "    'Metric': 'representational_independence',\n",
        "    'Baseline': rep_ind_results['Baseline']['representational_independence_score'],\n",
        "    'LAT': rep_ind_results['LAT']['representational_independence_score'],\n",
        "    'Expected': 'LAT > Baseline',\n",
        "    'Ratio (B/L)': rep_ind_results['Baseline']['representational_independence_score'] / max(rep_ind_results['LAT']['representational_independence_score'], 1e-10)\n",
        "})\n",
        "\n",
        "# Display summary\n",
        "summary_df = pd.DataFrame(summary_data)\n",
        "print(summary_df.to_string(index=False))\n",
        "\n",
        "# Interpretation\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"INTERPRETATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Check each hypothesis\n",
        "hypotheses_met = 0\n",
        "total_hypotheses = 0\n",
        "\n",
        "# 1. Interference should be lower in LAT\n",
        "total_hypotheses += 1\n",
        "if rsi_results['LAT']['mean_off_diagonal_interference'] < rsi_results['Baseline']['mean_off_diagonal_interference']:\n",
        "    hypotheses_met += 1\n",
        "    print(\"✓ Mean off-diagonal interference is LOWER in LAT (supports Gorton hypothesis)\")\n",
        "else:\n",
        "    print(\"✗ Mean off-diagonal interference is HIGHER in LAT (contradicts Gorton hypothesis)\")\n",
        "\n",
        "# 2. Effective dimension should be lower in LAT\n",
        "total_hypotheses += 1\n",
        "if erd_results['LAT']['effective_dimension_entropy'] < erd_results['Baseline']['effective_dimension_entropy']:\n",
        "    hypotheses_met += 1\n",
        "    print(\"✓ Effective dimension is LOWER in LAT (more concentrated representation)\")\n",
        "else:\n",
        "    print(\"✗ Effective dimension is HIGHER in LAT (less concentrated)\")\n",
        "\n",
        "# 3. Top-1 variance should be higher in LAT\n",
        "total_hypotheses += 1\n",
        "if erd_results['LAT']['top_1_variance_ratio'] > erd_results['Baseline']['top_1_variance_ratio']:\n",
        "    hypotheses_met += 1\n",
        "    print(\"✓ Top-1 variance ratio is HIGHER in LAT (simpler structure)\")\n",
        "else:\n",
        "    print(\"✗ Top-1 variance ratio is LOWER in LAT\")\n",
        "\n",
        "# 4. Growth rate should be lower in LAT\n",
        "total_hypotheses += 1\n",
        "if lat_growth < baseline_growth:\n",
        "    hypotheses_met += 1\n",
        "    print(\"✓ Interference growth rate is LOWER in LAT (slower propagation)\")\n",
        "else:\n",
        "    print(\"✗ Interference growth rate is HIGHER in LAT\")\n",
        "\n",
        "# 5. Representational independence should be higher in LAT\n",
        "total_hypotheses += 1\n",
        "if rep_ind_results['LAT']['representational_independence_score'] > rep_ind_results['Baseline']['representational_independence_score']:\n",
        "    hypotheses_met += 1\n",
        "    print(\"✓ Representational independence is HIGHER in LAT\")\n",
        "else:\n",
        "    print(\"✗ Representational independence is LOWER in LAT\")\n",
        "\n",
        "print(f\"\\nHypotheses supported: {hypotheses_met}/{total_hypotheses}\")\n",
        "print(\"\\nConclusion: \", end=\"\")\n",
        "if hypotheses_met >= 4:\n",
        "    print(\"Strong evidence that LAT reduces superposition similarly to adversarial training\")\n",
        "elif hypotheses_met >= 2:\n",
        "    print(\"Partial evidence for LAT reducing superposition\")\n",
        "else:\n",
        "    print(\"Limited/no evidence for LAT operating like adversarial training in this framework\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00f2a5d5",
      "metadata": {},
      "source": [
        "---\n",
        "## IGNORE FOR NOW: GRAM MATRIX AND INTERFERENCE ANALYSIS\n",
        "The Gram matrix G = D @ D^T captures pairwise similarities between difference directions. Off-diagonal elements measure \"interference\" - how much different prompts' refusal directions overlap.\n",
        "\n",
        "**Key metrics:**\n",
        "- Mean off-diagonal: Average |G_ij| for i ≠ j (lower = less interference)\n",
        "- Interference Frobenius: ||G - diag(G)||_F (total interference magnitude)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "033dee1f",
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_gram_matrix(directions: torch.Tensor, normalize: bool = True) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Compute Gram matrix G = D @ D^T\n",
        "    If normalize=True, computes cosine similarity matrix instead.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        norms = directions.norm(dim=1, keepdim=True)\n",
        "        norms = torch.clamp(norms, min=1e-8)\n",
        "        directions_normed = directions / norms\n",
        "        gram = directions_normed @ directions_normed.T\n",
        "    else:\n",
        "        gram = directions @ directions.T\n",
        "    return gram\n",
        "\n",
        "\n",
        "def compute_interference_metrics(gram: torch.Tensor) -> dict:\n",
        "    \"\"\"\n",
        "    Compute interference metrics from Gram matrix.\n",
        "    \"\"\"\n",
        "    n = gram.shape[0]\n",
        "    \n",
        "    # Extract off-diagonal elements\n",
        "    mask = ~torch.eye(n, dtype=torch.bool, device=gram.device)\n",
        "    off_diag = gram[mask]\n",
        "    \n",
        "    # Mean off-diagonal magnitude\n",
        "    mean_off_diagonal = off_diag.abs().mean().item()\n",
        "    \n",
        "    # Interference Frobenius norm: ||G - diag(G)||_F\n",
        "    diag_matrix = torch.diag(torch.diag(gram))\n",
        "    interference_frobenius = (gram - diag_matrix).norm('fro').item()\n",
        "    \n",
        "    # Standard deviation of off-diagonal\n",
        "    off_diagonal_std = off_diag.std().item()\n",
        "    \n",
        "    return {\n",
        "        'mean_off_diagonal': mean_off_diagonal,\n",
        "        'interference_frobenius': interference_frobenius,\n",
        "        'off_diagonal_std': off_diagonal_std,\n",
        "        'off_diagonal_values': off_diag.cpu().numpy()\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590f2a9a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute Gram matrix and interference for BOTH models at layer 14\n",
        "interference_results = {}\n",
        "\n",
        "for model_name in models.keys():\n",
        "    # Compute difference directions\n",
        "    directions = compute_difference_directions(harmful_acts[model_name], harmless_acts[model_name])\n",
        "    \n",
        "    # Compute normalized Gram matrix (cosine similarities)\n",
        "    gram = compute_gram_matrix(directions, normalize=True)\n",
        "    \n",
        "    # Compute interference metrics\n",
        "    interference = compute_interference_metrics(gram)\n",
        "    interference['gram'] = gram\n",
        "    interference['directions'] = directions\n",
        "    interference_results[model_name] = interference\n",
        "\n",
        "# Print comparison\n",
        "print(\"=\"*60)\n",
        "print(f\"Interference Metrics at Layer {TARGET_LAYER}\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Metric':<30} {'Baseline':<15} {'LAT':<15}\")\n",
        "print(\"-\"*60)\n",
        "for metric in ['mean_off_diagonal', 'interference_frobenius', 'off_diagonal_std']:\n",
        "    base = interference_results['Baseline'][metric]\n",
        "    lat = interference_results['LAT'][metric]\n",
        "    print(f\"{metric:<30} {base:<15.4f} {lat:<15.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10305fd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize Gram matrices for BOTH models\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "\n",
        "for idx, model_name in enumerate(models.keys()):\n",
        "    gram = interference_results[model_name]['gram']\n",
        "    off_diag = interference_results[model_name]['off_diagonal_values']\n",
        "    \n",
        "    # Gram matrix heatmap\n",
        "    im = axes[idx, 0].imshow(gram.cpu().numpy(), cmap='RdBu_r', vmin=-1, vmax=1)\n",
        "    axes[idx, 0].set_title(f'{model_name}: Cosine Similarity Matrix', fontsize=12)\n",
        "    axes[idx, 0].set_xlabel('Prompt Pair Index')\n",
        "    axes[idx, 0].set_ylabel('Prompt Pair Index')\n",
        "    plt.colorbar(im, ax=axes[idx, 0], label='Cosine Similarity')\n",
        "    \n",
        "    # Histogram of off-diagonal values\n",
        "    axes[idx, 1].hist(off_diag, bins=50, edgecolor='black', alpha=0.7, \n",
        "                      color='blue' if model_name == 'Baseline' else 'orange')\n",
        "    axes[idx, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero')\n",
        "    axes[idx, 1].axvline(x=off_diag.mean(), color='green', linestyle='--', linewidth=2, \n",
        "                         label=f'Mean: {off_diag.mean():.3f}')\n",
        "    mean_abs = interference_results[model_name]['mean_off_diagonal']\n",
        "    axes[idx, 1].set_title(f'{model_name}: Off-Diagonal Distribution\\nMean |sim|: {mean_abs:.3f}', fontsize=12)\n",
        "    axes[idx, 1].set_xlabel('Cosine Similarity')\n",
        "    axes[idx, 1].set_ylabel('Count')\n",
        "    axes[idx, 1].legend()\n",
        "    axes[idx, 1].grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(OUTPUT_DIR / f'gram_matrix_layer{TARGET_LAYER}_comparison.png', dpi=150)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
