{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -q sae-lens safetensors numpy matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sae_lens import SAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "BASELINE_SAE_ID = \"hal2k/llama2-7b-chat-sae-layer14-x16-pile\"\n",
        "LAT_SAE_ID = \"hal2k/llama2-7b-chat-lat-sae-layer14-x16-pile\"\n",
        "OUTPUT_DIR = \"./interference_outputs\"\n",
        "\n",
        "import os\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "baseline_sae = SAE.from_pretrained(release=BASELINE_SAE_ID, sae_id=\".\")[0]\n",
        "lat_sae = SAE.from_pretrained(release=LAT_SAE_ID, sae_id=\".\")[0]\n",
        "\n",
        "print(f\"Baseline SAE: {baseline_sae.W_dec.shape}\")\n",
        "print(f\"LAT SAE: {lat_sae.W_dec.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Extract & normalize decoder weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W_baseline = baseline_sae.W_dec.detach().cpu().numpy()  # (65536, 4096)\n",
        "W_lat = lat_sae.W_dec.detach().cpu().numpy()\n",
        "\n",
        "# Normalize to unit vectors\n",
        "W_baseline_norm = W_baseline / (np.linalg.norm(W_baseline, axis=1, keepdims=True) + 1e-8)\n",
        "W_lat_norm = W_lat / (np.linalg.norm(W_lat, axis=1, keepdims=True) + 1e-8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compute Gram matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G_baseline = W_baseline_norm @ W_baseline_norm.T\n",
        "G_lat = W_lat_norm @ W_lat_norm.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract off-diagonal (all pairwise interferences)\n",
        "n = G_baseline.shape[0]\n",
        "mask = ~np.eye(n, dtype=bool)\n",
        "off_diag_baseline = np.abs(G_baseline[mask])\n",
        "off_diag_lat = np.abs(G_lat[mask])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Compute interference metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dead features check\n",
        "baseline_norms = np.linalg.norm(W_baseline, axis=1)\n",
        "lat_norms = np.linalg.norm(W_lat, axis=1)\n",
        "baseline_dead_frac = np.mean(baseline_norms < 1e-6)\n",
        "lat_dead_frac = np.mean(lat_norms < 1e-6)\n",
        "\n",
        "# Interference stats\n",
        "baseline_mean = np.mean(off_diag_baseline)\n",
        "baseline_median = np.median(off_diag_baseline)\n",
        "baseline_max = np.max(off_diag_baseline)\n",
        "baseline_p95 = np.percentile(off_diag_baseline, 95)\n",
        "baseline_p99 = np.percentile(off_diag_baseline, 99)\n",
        "baseline_below_01 = np.mean(off_diag_baseline < 0.1)\n",
        "baseline_below_005 = np.mean(off_diag_baseline < 0.05)\n",
        "\n",
        "lat_mean = np.mean(off_diag_lat)\n",
        "lat_median = np.median(off_diag_lat)\n",
        "lat_max = np.max(off_diag_lat)\n",
        "lat_p95 = np.percentile(off_diag_lat, 95)\n",
        "lat_p99 = np.percentile(off_diag_lat, 99)\n",
        "lat_below_01 = np.mean(off_diag_lat < 0.1)\n",
        "lat_below_005 = np.mean(off_diag_lat < 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"{'Metric':<25} {'Baseline':>12} {'LAT':>12} {'Ratio':>10}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'mean_interference':<25} {baseline_mean:>12.6f} {lat_mean:>12.6f} {lat_mean/baseline_mean:>10.3f}\")\n",
        "print(f\"{'median_interference':<25} {baseline_median:>12.6f} {lat_median:>12.6f} {lat_median/baseline_median:>10.3f}\")\n",
        "print(f\"{'max_interference':<25} {baseline_max:>12.6f} {lat_max:>12.6f} {lat_max/baseline_max:>10.3f}\")\n",
        "print(f\"{'p95_interference':<25} {baseline_p95:>12.6f} {lat_p95:>12.6f} {lat_p95/baseline_p95:>10.3f}\")\n",
        "print(f\"{'p99_interference':<25} {baseline_p99:>12.6f} {lat_p99:>12.6f} {lat_p99/baseline_p99:>10.3f}\")\n",
        "print(f\"{'frac_below_0.1':<25} {baseline_below_01:>12.6f} {lat_below_01:>12.6f} {lat_below_01/baseline_below_01:>10.3f}\")\n",
        "print(f\"{'frac_below_0.05':<25} {baseline_below_005:>12.6f} {lat_below_005:>12.6f} {lat_below_005/baseline_below_005:>10.3f}\")\n",
        "print(f\"{'dead_features_frac':<25} {baseline_dead_frac:>12.6f} {lat_dead_frac:>12.6f} {'-':>10}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ratio = lat_mean / baseline_mean\n",
        "print(f\"\\nMean interference ratio (LAT/Baseline): {ratio:.3f}\")\n",
        "print(f\"Gorton et al. benchmark: robust models have ~0.5x the interference of non-robust\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Visualize interference distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Histograms\n",
        "axes[0].hist(off_diag_baseline, bins=100, alpha=0.7, label='Baseline', density=True)\n",
        "axes[0].hist(off_diag_lat, bins=100, alpha=0.7, label='LAT', density=True)\n",
        "axes[0].set_xlabel('|cos(feature_i, feature_j)|')\n",
        "axes[0].set_ylabel('Density')\n",
        "axes[0].set_title('Feature Interference Distribution')\n",
        "axes[0].legend()\n",
        "axes[0].set_xlim(0, 0.5)\n",
        "\n",
        "# CDFs\n",
        "for data, label in [(off_diag_baseline, 'Baseline'), (off_diag_lat, 'LAT')]:\n",
        "    sorted_data = np.sort(data)\n",
        "    cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
        "    step = len(sorted_data) // 10000  # subsample for plotting\n",
        "    axes[1].plot(sorted_data[::step], cdf[::step], label=label)\n",
        "\n",
        "axes[1].set_xlabel('|cos(feature_i, feature_j)|')\n",
        "axes[1].set_ylabel('CDF')\n",
        "axes[1].set_title('Cumulative Distribution')\n",
        "axes[1].legend()\n",
        "axes[1].set_xlim(0, 0.3)\n",
        "axes[1].axhline(0.95, color='gray', linestyle='--', alpha=0.5)\n",
        "axes[1].axhline(0.99, color='gray', linestyle='--', alpha=0.5)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(f\"{OUTPUT_DIR}/interference_comparison.png\", dpi=150)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
