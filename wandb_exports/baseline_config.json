{
  "lr": 0.0001,
  "sae": {
    "k": 64,
    "d_in": 4096,
    "d_sae": 65536,
    "dtype": "float32",
    "device": "cpu",
    "metadata": {
      "sae_lens_version": "6.27.1",
      "sae_lens_training_version": "6.27.1"
    },
    "architecture": "batchtopk",
    "decoder_init_norm": 0.1,
    "topk_threshold_lr": 0.01,
    "reshape_activations": "none",
    "apply_b_dec_to_input": true,
    "aux_loss_coefficient": 1,
    "normalize_activations": "none",
    "use_sparse_activations": false,
    "rescale_acts_by_decoder_norm": true
  },
  "seed": 42,
  "dtype": "float32",
  "device": "cuda",
  "logger": {
    "run_name": "baseline-layer14-sae",
    "wandb_id": null,
    "log_to_wandb": true,
    "wandb_entity": null,
    "wandb_project": "lat-interference-analysis",
    "wandb_log_frequency": 10,
    "eval_every_n_wandb_logs": 100,
    "log_optimizer_state_to_wandb": false,
    "log_activations_store_to_wandb": false
  },
  "lr_end": 1e-05,
  "verbose": true,
  "autocast": true,
  "hook_eval": "NOT_IN_USE",
  "hook_name": "blocks.14.hook_resid_post",
  "streaming": true,
  "adam_beta1": 0.9,
  "adam_beta2": 0.999,
  "model_name": "meta-llama/Llama-2-7b-chat-hf",
  "autocast_lm": true,
  "compile_llm": false,
  "compile_sae": false,
  "output_path": "output",
  "prepend_bos": true,
  "context_size": 512,
  "dataset_path": "monology/pile-uncopyrighted",
  "seqpos_slice": [
    null
  ],
  "n_checkpoints": 3,
  "lr_decay_steps": 0,
  "n_eval_batches": 10,
  "checkpoint_path": "./sae_outputs/baseline_checkpoints/qaofpmxi",
  "hook_head_index": null,
  "training_tokens": 100000000,
  "act_store_device": "cuda",
  "lr_warm_up_steps": 0,
  "model_class_name": "HookedTransformer",
  "n_restart_cycles": 1,
  "sae_lens_version": "6.27.1",
  "lr_scheduler_name": "constant",
  "dead_feature_window": 1000,
  "n_batches_in_buffer": 32,
  "from_pretrained_path": null,
  "is_dataset_tokenized": true,
  "llm_compilation_mode": null,
  "sae_compilation_mode": null,
  "save_final_checkpoint": false,
  "dead_feature_threshold": 1e-08,
  "exclude_special_tokens": false,
  "resume_from_checkpoint": null,
  "use_cached_activations": false,
  "cached_activations_path": null,
  "eval_batch_size_prompts": null,
  "feature_sampling_window": 2000,
  "train_batch_size_tokens": 4096,
  "disable_concat_sequences": false,
  "sequence_separator_token": "bos",
  "store_batch_size_prompts": 16,
  "dataset_trust_remote_code": true,
  "sae_lens_training_version": "6.27.1",
  "activations_mixing_fraction": 0.5,
  "model_from_pretrained_kwargs": {
    "center_writing_weights": false
  }
}