{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa6a532",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba47e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from transformer_lens import HookedTransformer\n",
    "from transformers import AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from huggingface_hub import login as hf_login\n",
    "from sae_lens import SAE\n",
    "\n",
    "load_dotenv()\n",
    "hf_login(token=os.environ.get('HF_TOKEN'))\n",
    "\n",
    "def clear_gpu():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60459eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "LLAMA_PATH = 'meta-llama/Llama-2-7b-chat-hf'\n",
    "LAT_PATH = 'nlpett/llama-2-7b-chat-hf-LAT-layer4-hh'\n",
    "TEMPLATE = '\\n[INST]{prompt}[/INST]\\n'\n",
    "\n",
    "BASELINE_SAE_PATH = './sae_outputs/baseline_sae_final'\n",
    "LAT_SAE_PATH = './sae_outputs/lat_sae_final'\n",
    "\n",
    "LAYER = 14\n",
    "D_SAE = 65536\n",
    "K = 64\n",
    "N_SAMPLES = 200\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408846a1",
   "metadata": {},
   "source": [
    "#### Load harmful/harmless prompts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5485c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/llm-attacks/llm-attacks/main/data/advbench/harmful_behaviors.csv'\n",
    "harmful_all = pd.read_csv(io.StringIO(requests.get(url).content.decode('utf-8')))['goal'].tolist()\n",
    "harmful_train, _ = train_test_split(harmful_all, test_size=0.2, random_state=42)\n",
    "\n",
    "dataset = load_dataset('tatsu-lab/alpaca')\n",
    "harmless_all = [dataset['train'][i]['instruction'] for i in range(len(dataset['train'])) \n",
    "                if dataset['train'][i]['input'].strip() == '']\n",
    "harmless_train, _ = train_test_split(harmless_all, test_size=0.2, random_state=42)\n",
    "\n",
    "harmful_prompts = harmful_train[:N_SAMPLES]\n",
    "harmless_prompts = harmless_train[:N_SAMPLES]\n",
    "print(f\"{len(harmful_prompts)} harmful, {len(harmless_prompts)} harmless\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea70b8d",
   "metadata": {},
   "source": [
    "#### Baseline model + SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d922f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_hf = AutoModelForCausalLM.from_pretrained(LLAMA_PATH, torch_dtype=torch.float16, device_map='auto')\n",
    "baseline_model = HookedTransformer.from_pretrained_no_processing(\n",
    "    LLAMA_PATH, hf_model=base_hf, dtype=torch.float16, device=DEVICE, default_padding_side='left')\n",
    "baseline_model.tokenizer.padding_side = 'left'\n",
    "baseline_model.tokenizer.pad_token = '[PAD]'\n",
    "del base_hf\n",
    "clear_gpu()\n",
    "\n",
    "baseline_sae = SAE.load_from_pretrained(BASELINE_SAE_PATH, device=DEVICE)\n",
    "baseline_sae.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4514f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_harmful_l1s = []\n",
    "baseline_harmful_recon_errors = []\n",
    "baseline_harmful_top_features = []\n",
    "\n",
    "for i in tqdm(range(0, len(harmful_prompts), BATCH_SIZE)):\n",
    "    batch = harmful_prompts[i:i+BATCH_SIZE]\n",
    "    prompts = [TEMPLATE.format(prompt=p) for p in batch]\n",
    "    toks = baseline_model.tokenizer(prompts, padding=True, return_tensors='pt').input_ids.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = baseline_model.run_with_cache(toks, names_filter=lambda n: f'blocks.{LAYER}.hook_resid_post' in n)\n",
    "        acts = cache[f'blocks.{LAYER}.hook_resid_post'][:, -1, :]\n",
    "        sae_acts = baseline_sae.encode(acts)\n",
    "        recon = baseline_sae.decode(sae_acts)\n",
    "        \n",
    "        baseline_harmful_l1s.extend(sae_acts.abs().sum(dim=-1).cpu().tolist())\n",
    "        baseline_harmful_recon_errors.extend(((acts - recon) ** 2).mean(dim=-1).cpu().tolist())\n",
    "        \n",
    "        for j in range(sae_acts.shape[0]):\n",
    "            active_idx = (sae_acts[j].abs() > 1e-8).nonzero(as_tuple=True)[0]\n",
    "            baseline_harmful_top_features.append(active_idx.cpu().tolist())\n",
    "    \n",
    "    del cache, acts, sae_acts, recon\n",
    "    clear_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf4d9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_harmless_l1s = []\n",
    "baseline_harmless_recon_errors = []\n",
    "baseline_harmless_top_features = []\n",
    "\n",
    "for i in tqdm(range(0, len(harmless_prompts), BATCH_SIZE)):\n",
    "    batch = harmless_prompts[i:i+BATCH_SIZE]\n",
    "    prompts = [TEMPLATE.format(prompt=p) for p in batch]\n",
    "    toks = baseline_model.tokenizer(prompts, padding=True, return_tensors='pt').input_ids.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = baseline_model.run_with_cache(toks, names_filter=lambda n: f'blocks.{LAYER}.hook_resid_post' in n)\n",
    "        acts = cache[f'blocks.{LAYER}.hook_resid_post'][:, -1, :]\n",
    "        sae_acts = baseline_sae.encode(acts)\n",
    "        recon = baseline_sae.decode(sae_acts)\n",
    "        \n",
    "        baseline_harmless_l1s.extend(sae_acts.abs().sum(dim=-1).cpu().tolist())\n",
    "        baseline_harmless_recon_errors.extend(((acts - recon) ** 2).mean(dim=-1).cpu().tolist())\n",
    "        \n",
    "        for j in range(sae_acts.shape[0]):\n",
    "            active_idx = (sae_acts[j].abs() > 1e-8).nonzero(as_tuple=True)[0]\n",
    "            baseline_harmless_top_features.append(active_idx.cpu().tolist())\n",
    "    \n",
    "    del cache, acts, sae_acts, recon\n",
    "    clear_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab82e215",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_harmful_l1 = np.mean(baseline_harmful_l1s)\n",
    "baseline_harmless_l1 = np.mean(baseline_harmless_l1s)\n",
    "baseline_l1_ratio = baseline_harmful_l1 / baseline_harmless_l1\n",
    "baseline_harmful_mse = np.mean(baseline_harmful_recon_errors)\n",
    "baseline_harmless_mse = np.mean(baseline_harmless_recon_errors)\n",
    "\n",
    "baseline_harmful_counts = np.zeros(D_SAE)\n",
    "baseline_harmless_counts = np.zeros(D_SAE)\n",
    "for feats in baseline_harmful_top_features:\n",
    "    for f in feats:\n",
    "        baseline_harmful_counts[f] += 1\n",
    "for feats in baseline_harmless_top_features:\n",
    "    for f in feats:\n",
    "        baseline_harmless_counts[f] += 1\n",
    "\n",
    "baseline_harmful_specific = np.argsort(baseline_harmful_counts - baseline_harmless_counts)[-20:]\n",
    "baseline_harmless_specific = np.argsort(baseline_harmless_counts - baseline_harmful_counts)[-20:]\n",
    "baseline_top_harmful = set(np.argsort(baseline_harmful_counts)[-100:])\n",
    "baseline_top_harmless = set(np.argsort(baseline_harmless_counts)[-100:])\n",
    "baseline_jaccard = len(baseline_top_harmful & baseline_top_harmless) / len(baseline_top_harmful | baseline_top_harmless)\n",
    "\n",
    "print(f\"Harmful L1:  {baseline_harmful_l1:.1f} ± {np.std(baseline_harmful_l1s):.1f}\")\n",
    "print(f\"Harmless L1: {baseline_harmless_l1:.1f} ± {np.std(baseline_harmless_l1s):.1f}\")\n",
    "print(f\"L1 Ratio:    {baseline_l1_ratio:.3f}\")\n",
    "print(f\"Harmful MSE: {baseline_harmful_mse:.4f}\")\n",
    "print(f\"Harmless MSE:{baseline_harmless_mse:.4f}\")\n",
    "print(f\"Jaccard:     {baseline_jaccard:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "del baseline_model, baseline_sae\n",
    "clear_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c4e66f",
   "metadata": {},
   "source": [
    "#### LAT model + SAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_base = AutoModelForCausalLM.from_pretrained(LLAMA_PATH, torch_dtype=torch.float16, device_map='auto')\n",
    "lat_peft = PeftModel.from_pretrained(lat_base, LAT_PATH).to(torch.float16)\n",
    "lat_hf = lat_peft.merge_and_unload()\n",
    "lat_hf.eval()\n",
    "del lat_peft\n",
    "\n",
    "lat_model = HookedTransformer.from_pretrained_no_processing(\n",
    "    LLAMA_PATH, hf_model=lat_hf, dtype=torch.float16, device=DEVICE, default_padding_side='left')\n",
    "lat_model.tokenizer.padding_side = 'left'\n",
    "lat_model.tokenizer.pad_token = '[PAD]'\n",
    "del lat_base, lat_hf\n",
    "clear_gpu()\n",
    "\n",
    "lat_sae = SAE.load_from_pretrained(LAT_SAE_PATH, device=DEVICE)\n",
    "lat_sae.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fd0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_harmful_l1s = []\n",
    "lat_harmful_recon_errors = []\n",
    "lat_harmful_top_features = []\n",
    "\n",
    "for i in tqdm(range(0, len(harmful_prompts), BATCH_SIZE)):\n",
    "    batch = harmful_prompts[i:i+BATCH_SIZE]\n",
    "    prompts = [TEMPLATE.format(prompt=p) for p in batch]\n",
    "    toks = lat_model.tokenizer(prompts, padding=True, return_tensors='pt').input_ids.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = lat_model.run_with_cache(toks, names_filter=lambda n: f'blocks.{LAYER}.hook_resid_post' in n)\n",
    "        acts = cache[f'blocks.{LAYER}.hook_resid_post'][:, -1, :]\n",
    "        sae_acts = lat_sae.encode(acts)\n",
    "        recon = lat_sae.decode(sae_acts)\n",
    "        \n",
    "        lat_harmful_l1s.extend(sae_acts.abs().sum(dim=-1).cpu().tolist())\n",
    "        lat_harmful_recon_errors.extend(((acts - recon) ** 2).mean(dim=-1).cpu().tolist())\n",
    "        \n",
    "        for j in range(sae_acts.shape[0]):\n",
    "            active_idx = (sae_acts[j].abs() > 1e-8).nonzero(as_tuple=True)[0]\n",
    "            lat_harmful_top_features.append(active_idx.cpu().tolist())\n",
    "    \n",
    "    del cache, acts, sae_acts, recon\n",
    "    clear_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad9885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_harmless_l1s = []\n",
    "lat_harmless_recon_errors = []\n",
    "lat_harmless_top_features = []\n",
    "\n",
    "for i in tqdm(range(0, len(harmless_prompts), BATCH_SIZE)):\n",
    "    batch = harmless_prompts[i:i+BATCH_SIZE]\n",
    "    prompts = [TEMPLATE.format(prompt=p) for p in batch]\n",
    "    toks = lat_model.tokenizer(prompts, padding=True, return_tensors='pt').input_ids.to(DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        _, cache = lat_model.run_with_cache(toks, names_filter=lambda n: f'blocks.{LAYER}.hook_resid_post' in n)\n",
    "        acts = cache[f'blocks.{LAYER}.hook_resid_post'][:, -1, :]\n",
    "        sae_acts = lat_sae.encode(acts)\n",
    "        recon = lat_sae.decode(sae_acts)\n",
    "        \n",
    "        lat_harmless_l1s.extend(sae_acts.abs().sum(dim=-1).cpu().tolist())\n",
    "        lat_harmless_recon_errors.extend(((acts - recon) ** 2).mean(dim=-1).cpu().tolist())\n",
    "        \n",
    "        for j in range(sae_acts.shape[0]):\n",
    "            active_idx = (sae_acts[j].abs() > 1e-8).nonzero(as_tuple=True)[0]\n",
    "            lat_harmless_top_features.append(active_idx.cpu().tolist())\n",
    "    \n",
    "    del cache, acts, sae_acts, recon\n",
    "    clear_gpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb33fda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_harmful_l1 = np.mean(lat_harmful_l1s)\n",
    "lat_harmless_l1 = np.mean(lat_harmless_l1s)\n",
    "lat_l1_ratio = lat_harmful_l1 / lat_harmless_l1\n",
    "lat_harmful_mse = np.mean(lat_harmful_recon_errors)\n",
    "lat_harmless_mse = np.mean(lat_harmless_recon_errors)\n",
    "\n",
    "lat_harmful_counts = np.zeros(D_SAE)\n",
    "lat_harmless_counts = np.zeros(D_SAE)\n",
    "for feats in lat_harmful_top_features:\n",
    "    for f in feats:\n",
    "        lat_harmful_counts[f] += 1\n",
    "for feats in lat_harmless_top_features:\n",
    "    for f in feats:\n",
    "        lat_harmless_counts[f] += 1\n",
    "\n",
    "lat_harmful_specific = np.argsort(lat_harmful_counts - lat_harmless_counts)[-20:]\n",
    "lat_harmless_specific = np.argsort(lat_harmless_counts - lat_harmful_counts)[-20:]\n",
    "lat_top_harmful = set(np.argsort(lat_harmful_counts)[-100:])\n",
    "lat_top_harmless = set(np.argsort(lat_harmless_counts)[-100:])\n",
    "lat_jaccard = len(lat_top_harmful & lat_top_harmless) / len(lat_top_harmful | lat_top_harmless)\n",
    "\n",
    "print(f\"Harmful L1:  {lat_harmful_l1:.1f} ± {np.std(lat_harmful_l1s):.1f}\")\n",
    "print(f\"Harmless L1: {lat_harmless_l1:.1f} ± {np.std(lat_harmless_l1s):.1f}\")\n",
    "print(f\"L1 Ratio:    {lat_l1_ratio:.3f}\")\n",
    "print(f\"Harmful MSE: {lat_harmful_mse:.4f}\")\n",
    "print(f\"Harmless MSE:{lat_harmless_mse:.4f}\")\n",
    "print(f\"Jaccard:     {lat_jaccard:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce9a0a",
   "metadata": {},
   "source": [
    "#### Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b493f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_base, p_base = stats.ttest_ind(baseline_harmful_l1s, baseline_harmless_l1s)\n",
    "t_lat, p_lat = stats.ttest_ind(lat_harmful_l1s, lat_harmless_l1s)\n",
    "\n",
    "print(f\"{'':25} {'Baseline':>12} {'LAT':>12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Harmful L1':<25} {baseline_harmful_l1:>12.1f} {lat_harmful_l1:>12.1f}\")\n",
    "print(f\"{'Harmless L1':<25} {baseline_harmless_l1:>12.1f} {lat_harmless_l1:>12.1f}\")\n",
    "print(f\"{'L1 Ratio':<25} {baseline_l1_ratio:>12.3f} {lat_l1_ratio:>12.3f}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Harmful MSE':<25} {baseline_harmful_mse:>12.4f} {lat_harmful_mse:>12.4f}\")\n",
    "print(f\"{'Harmless MSE':<25} {baseline_harmless_mse:>12.4f} {lat_harmless_mse:>12.4f}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Feature Jaccard':<25} {baseline_jaccard:>12.3f} {lat_jaccard:>12.3f}\")\n",
    "print(f\"{'t-stat (harmful vs less)':<25} {t_base:>12.2f} {t_lat:>12.2f}\")\n",
    "print(f\"{'p-value':<25} {p_base:>12.2e} {p_lat:>12.2e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44c9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    'config': {'n_samples': N_SAMPLES, 'layer': LAYER, 'topk': K, 'd_sae': D_SAE},\n",
    "    'baseline': {\n",
    "        'harmful_l1': baseline_harmful_l1, 'harmless_l1': baseline_harmless_l1,\n",
    "        'l1_ratio': baseline_l1_ratio, 'harmful_mse': baseline_harmful_mse,\n",
    "        'harmless_mse': baseline_harmless_mse, 'jaccard': baseline_jaccard,\n",
    "        'harmful_specific': baseline_harmful_specific.tolist(),\n",
    "        'harmless_specific': baseline_harmless_specific.tolist(),\n",
    "        't_stat': float(t_base), 'p_val': float(p_base),\n",
    "    },\n",
    "    'lat': {\n",
    "        'harmful_l1': lat_harmful_l1, 'harmless_l1': lat_harmless_l1,\n",
    "        'l1_ratio': lat_l1_ratio, 'harmful_mse': lat_harmful_mse,\n",
    "        'harmless_mse': lat_harmless_mse, 'jaccard': lat_jaccard,\n",
    "        'harmful_specific': lat_harmful_specific.tolist(),\n",
    "        'harmless_specific': lat_harmless_specific.tolist(),\n",
    "        't_stat': float(t_lat), 'p_val': float(p_lat),\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('sae_l1_analysis_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "print(\"Saved to sae_l1_analysis_results.json\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
